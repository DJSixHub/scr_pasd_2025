services:
  # Ray head node (handles both training and serving)
  ray-head:
    build: .
    ports:
      - "8000:8000"  # API port
      - "8265:8265"  # Ray dashboard
      - "10001:10001"  # Ray client server
      - "6379:6379"  # Redis
    command: >
      bash -c "ray start --head --port=6379 --dashboard-host=0.0.0.0 --dashboard-port=8265 --block &
              sleep 5 &&
              python main.py --mode=all --data /app/data/iris.csv --data /app/data/wine.csv --data /app/data/breast_cancer.csv --target=target --output-dir=/app/output --host=0.0.0.0 --port=8000 --ray-redundancy=2 --failure-tolerant &&
              echo 'Keeping container alive to serve API requests...' &&
              tail -f /dev/null"
    environment:
      - RAY_DISABLE_DOCKER_CPU_WARNING=1
      - PYTHONUNBUFFERED=1
    healthcheck:
      test: ["CMD", "ray", "status"]
      interval: 10s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 6G
      restart_policy:
        condition: on-failure
        max_attempts: 3

  # Ray worker nodes for distributed processing
  ray-worker-1:
    build: .
    depends_on:
      - ray-head
    command: >
      bash -c "sleep 10 && ray start --address=ray-head:6379 --block"
    environment:
      - RAY_DISABLE_DOCKER_CPU_WARNING=1
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 3G
      restart_policy:
        condition: on-failure
        max_attempts: 3

  ray-worker-2:
    build: .
    depends_on:
      - ray-head
    command: >
      bash -c "sleep 12 && ray start --address=ray-head:6379 --block"
    environment:
      - RAY_DISABLE_DOCKER_CPU_WARNING=1
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 3G
      restart_policy:
        condition: on-failure
        max_attempts: 3
